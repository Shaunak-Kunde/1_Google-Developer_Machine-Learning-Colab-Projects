# Google Machine Learning Crash Course – Colab Projects

# Select path https://github.com/Shaunak-Kunde/1_Google-for-Developer_Machine-Learning-Colab-Projects/tree/main/ml/cc/exercises
# (Machine Learning Crash Course Labs Completed)

These notebooks are part of my learning journey during the Google for Developers Machine Learning Crash Course, completed as part of the SkillsWallet SmartInternz Virtual Internship Program. The course offered a practical, hands-on introduction to machine learning with interactive visualizations, exercises and Colab-based notebooks.

Unlike synthetic or preprocessed datasets from Kaggle, these exercises focus on building foundational ML skills, working with raw or real-world-like data, and applying machine learning concepts end-to-end.

# 📚 Projects / Notebooks
<img width="496" height="282" alt="image" src="https://github.com/user-attachments/assets/1cf5a89b-0934-4df9-b4b8-9f0e02f4d803" />

🚀 Key Learning Outcomes

Built regression and classification models from scratch, including linear and logistic regression.

Explored data preprocessing for numerical and categorical data using techniques like one-hot encoding and feature transformations.

Understood dataset characteristics, generalization, and overfitting.

Learned neural networks, embeddings, and an introduction to large language models (LLMs).

Explored production ML systems, AutoML, and responsible ML practices including fairness auditing.


## 🚀 Projects / Notebooks

Here is a summary of each notebook and the key concepts it demonstrates.

### `binary_classification_rice.ipynb`
-   **Summary:** This notebook walks through the process of building a binary classification model to predict the variety of a rice grain. Using a dataset of rice features like shape and size, it covers essential steps from data loading and feature analysis to training a logistic regression model. It concludes by evaluating the model's performance using key classification metrics like accuracy, precision, and recall.

### `fairness_income.ipynb`
-   **Summary:** This project explores the critical concept of fairness in machine learning. It involves training a classification model to predict whether an individual's income exceeds a certain threshold. The core of the lab is to then audit this model for bias across different sensitive attributes (like gender or race), demonstrating how to identify and measure fairness disparities using common metrics.

### `linear_regression_taxi.ipynb`
-   **Summary:** This notebook serves as a fundamental introduction to regression models. It uses a real-world-like taxi trip dataset to build a linear regression model that predicts a continuous value, such as the fare amount based on trip distance. Key steps include feature engineering, training the model, and evaluating its performance by analyzing loss metrics like Root Mean Squared Error (RMSE).

### `numerical_data_bad_values.ipynb`
-   **Summary:** A practical data cleaning exercise, this notebook focuses on handling imperfections in numerical data, which is a critical preprocessing step. It demonstrates essential techniques for identifying and dealing with outliers, missing values, and other anomalies. The project shows how to apply methods like imputation (e.g., using the mean or median) and how these choices can impact model stability and performance.

### `numerical_data_stats.ipynb`
-   **Summary:** This notebook covers the first crucial step in any machine learning workflow: exploratory data analysis (EDA). It demonstrates how to analyze a numerical dataset using descriptive statistics to gain key insights. Activities include calculating metrics like mean, standard deviation, and quartiles, and creating visualizations like histograms to understand the data's distribution and characteristics before training a model.

---

## 🔑 Key Learning Outcomes
- Built regression and classification models from scratch, including linear and logistic regression.
- Explored data preprocessing for numerical and categorical data using techniques like one-hot encoding and feature transformations.
- Understood dataset characteristics, generalization, and overfitting.
- Learned neural networks, embeddings, and an introduction to large language models (LLMs).
- Explored production ML systems, AutoML, and responsible ML practices including fairness auditing.

## 🛠️ Tools & Libraries

-   **Python 3.x**
-   **Google Colab**
-   **NumPy, Pandas**
-   **Matplotlib, Seaborn**
-   **Scikit-learn**

## 📂 Repository Structure

ml/cc/exercises/
│
├── binary_classification_rice.ipynb
├── fairness_income.ipynb
├── linear_regression_taxi.ipynb
├── numerical_data_bad_values.ipynb
├── numerical_data_stats.ipynb
├── .gitattributes
└── README.md

All notebooks were created and executed in Google Colab.

Each notebook is self-contained, demonstrating a specific ML concept or workflow.

These projects collectively showcase practical application of ML fundamentals using Python.

---
